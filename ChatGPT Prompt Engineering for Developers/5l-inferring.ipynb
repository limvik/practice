{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring\n",
    "In this lesson, you will infer sentiment and topics from product reviews and news articles.\n",
    "\n",
    "---\n",
    "\n",
    "This next video is on inferring. I like to think of these tasks where the model takes a text as input and performs some kind of analysis. So this could be extracting labels, extracting names, kind of understanding the sentiment of a text, that kind of thing. \n",
    "\n",
    "다음 동영상은 추론에 관한 것입니다. 추론은 모델이 텍스트를 입력으로 받아 어떤 종류의 분석을 수행하는 작업이라고 생각하면 됩니다. 예를 들어 레이블 추출, 이름 추출, 텍스트의 감성을 이해하는 등의 작업을 할 수 있습니다.\n",
    "\n",
    "So if you want to extract a sentiment, positive or negative, with a piece of text, in the traditional machine learning workflow, you'd have to collect the label data set, train the model, figure out how to deploy the model somewhere in the cloud and make inferences.\n",
    "\n",
    "따라서 텍스트에서 긍정적이든 부정적이든 감정을 추출하려면 기존 머신 러닝 워크플로에서는 라벨 데이터 세트를 수집하고, 모델을 학습시키고, 클라우드 어딘가에 모델을 배포하고 추론하는 방법을 알아내야 합니다.\n",
    "\n",
    "And that can work pretty well, but it was just a lot of work to go through that process. And also for every task, such as sentiment versus extracting names versus something else, you have to train and deploy a separate model. One of the really nice things about a large language model is that for many tasks like these, you can just write a prompt and have it start generating results pretty much right away. And that gives tremendous speed in terms of application development.\n",
    "\n",
    "이 방법은 꽤 잘 작동할 수 있지만, 그 과정을 거치는 데는 많은 노력이 필요했습니다. 또한 감정 추출, 이름 추출, 다른 작업 등 모든 작업에 대해 별도의 모델을 학습하고 배포해야 했습니다. 대규모 언어 모델의 정말 좋은 점 중 하나는 이와 같은 많은 작업에서 프롬프트만 작성하면 바로 결과를 생성할 수 있다는 점입니다. 따라서 애플리케이션 개발 속도가 엄청나게 빨라집니다.\n",
    "\n",
    "And you can also just use one model, one API, to do many different tasks rather than needing to figure out how to train and deploy a lot of different models. And so with that, let's jump into the code to see how you can take advantage of this.\n",
    "\n",
    "또한 여러 가지 모델을 훈련하고 배포하는 방법을 알아낼 필요 없이 하나의 모델, 하나의 API를 사용하여 다양한 작업을 수행할 수 있습니다. 이제 이 기능을 어떻게 활용할 수 있는지 코드를 살펴보겠습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "So here's a usual starter code. I'll just run that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product review text\n",
    "\n",
    "And the most important example I'm going to use is a review for a lamp.So need a nice lamp for the bedroom, and this one additional storage, and so on.\n",
    "\n",
    "그리고 제가 사용할 가장 중요한 예는 램프에 대한 리뷰입니다. 침실에 멋진 램프가 필요하고, 이 수납장도 추가로 필요하고, 이런 식으로요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment (positive/negative)\n",
    "\n",
    "So let me write a prompt to classify the sentiment of this. And if I want the system to tell me, you know, what is the sentiment, I can just write what is the sentiment of the following product review, with the usual delimiter and the review text and so on. And let's run that.\n",
    "\n",
    "그래서 이것의 감정을 분류하는 프롬프트를 작성해 보겠습니다. 그리고 시스템에서 감성이 무엇인지 알려주길 원한다면 일반적인 구분 기호와 리뷰 텍스트 등을 사용하여 다음 제품 리뷰의 감성이 무엇인지 작성하면 됩니다. 그리고 실행해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment of the product review is positive.\n",
    "\n",
    "---\n",
    "\n",
    "And this says the sentiment of the product review is positive, which is actually seems pretty right. This lamp isn't perfect, but this customer seems pretty happy. Seems to be a great company that cares about the customers and products. I think positive sentiment seems like the right answer.\n",
    "\n",
    "제품 리뷰의 정서가 긍정적이라고 되어 있는데, 실제로는 꽤 맞는 것 같습니다. 이 램프가 완벽하지는 않지만 이 고객은 꽤 만족하는 것 같습니다. 고객과 제품을 생각하는 좋은 회사인 것 같습니다. 긍정적인 감성이 정답인 것 같습니다. \n",
    "\n",
    "If you wanted to give a more concise response to make it easier for post-processing, I can take this prompt and add another instruction to give you answers in a single word, either positive or negative. So it just prints out positive like this, which makes it easier for a piece of text to take this output and process it and do something with it.\n",
    "\n",
    "후처리를 더 쉽게 하기 위해 더 간결한 응답을 제공하려는 경우 이 프롬프트에 긍정 또는 부정 중 한 단어로 답변을 제공하도록 다른 명령을 추가할 수 있습니다. 그러면 이렇게 긍정적으로 출력되므로 텍스트 조각이 이 출력을 가져와서 처리하고 무언가를 수행하기가 더 쉬워집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive\n",
    "\n",
    "---\n",
    "\n",
    "## Identify types of emotions\n",
    "\n",
    "Let's look at another prompt, again still using the lamp review. Here, I have it identify a list of emotions that the writer of the following review is expressing, including no more than five items in this list. So, large language models are pretty good at extracting specific things out of a piece of text. In this case, we're expressing the emotions. And this could be useful for understanding how your customers think about a particular product.\n",
    "\n",
    "다시 한 번 램프 리뷰를 사용하는 다른 프롬프트를 살펴봅시다. 여기서는 다음 리뷰의 작성자가 표현하고 있는 감정 목록을 식별하도록 했는데, 이 목록에는 5개 이하의 항목이 포함되어 있습니다. 따라서 대규모 언어 모델은 텍스트에서 특정 내용을 추출하는 데 매우 능숙합니다. 이 경우에는 감정을 표현하고 있습니다. 이는 고객이 특정 제품에 대해 어떻게 생각하는지 이해하는 데 유용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "happy, satisfied, grateful, impressed, content\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a lot of customer support organizations, it's important to understand if a particular user is extremely upset. So you might have a different classification problem like this.\n",
    "\n",
    "많은 고객 지원 조직에서는 특정 사용자가 극도로 화를 내는지 파악하는 것이 중요합니다. 따라서 다음과 같은 다른 분류 문제가 있을 수 있습니다.\n",
    "\n",
    "## Identify anger\n",
    "\n",
    "Is the writer of the following review expressing anger? Because if someone is really angry, it might merit paying extra attention to have a customer review, to have customer support or customer success, reach out to figure what's going on and make things right for the customer. In this case, the customer is not angry. And notice that with supervised learning, if I had wanted to build all of these classifiers, there's no way I would have been able to do this with supervised learning in just a few minutes that you saw me do so in this video. I'd encourage you to pause this video and try changing some of these prompts. Maybe ask if the customer is expressing delight or ask if there are any missing parts and see if you can get a prompt to make different inferences about this lamp review.\n",
    "\n",
    "다음 리뷰 작성자가 분노를 표현하고 있나요? 정말 화가 난 사람이라면 고객 리뷰, 고객 지원팀 또는 고객 성공팀에 연락하여 무슨 일이 일어나고 있는지 파악하고 고객을 위해 문제를 바로잡는 데 더 많은 주의를 기울일 필요가 있을 수 있습니다. 이 경우 고객은 화를 내지 않습니다. 그리고 지도 학습을 통해 이 모든 분류기를 만들려고 했다면 이 동영상에서 보신 것처럼 단 몇 분 만에 지도 학습을 통해 이 작업을 수행할 수 없었을 것입니다. 이 동영상을 일시 중지하고 몇 가지 프롬프트를 변경해 보시기 바랍니다. 고객이 기쁨을 표현하고 있는지 물어보거나 누락된 부분이 있는지 물어보고 이 램프 리뷰에 대해 다른 추론을 할 수 있는 프롬프트를 얻을 수 있는지 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No\n",
    "\n",
    "---\n",
    "\n",
    "## Extract product and company name from customer reviews\n",
    "\n",
    "Let me show some more things that you can do with this system, uhm, specifically extracting richer information from a customer review. \n",
    "\n",
    "이 시스템으로 할 수 있는 일, 특히 고객 리뷰에서 더 풍부한 정보를 추출하는 방법을 몇 가지 더 보여드리겠습니다. \n",
    "\n",
    "So, information extraction is the part of NLP, of natural language processing, that relates to taking a piece of text and extracting certain things that you want to know from the text. So, in this prompt, I'm asking it, identify the following items, the item purchase, and the name of the company that made the item. Again, if you are trying to summarize many reviews from an online shopping e-commerce website, it might be useful for your large collection of reviews to figure out what were the items, who made the item, figure out positive and negative sentiment, to track trends about positive or negative sentiment for specific items or for specific manufacturers. And in this example, I'm going to ask it to format your response as a JSON object with item and brand as the keys.\n",
    "\n",
    "따라서 정보 추출은 자연어 처리의 일부인 NLP의 일부로, 텍스트를 가져와서 텍스트에서 알고 싶은 특정 사항을 추출하는 것과 관련이 있습니다. 따라서 이 프롬프트에서는 다음 품목, 구매 품목 및 해당 품목을 만든 회사 이름을 식별해 달라고 요청하고 있습니다. 다시 말하지만, 온라인 쇼핑 이커머스 웹사이트의 많은 리뷰를 요약하려는 경우 대량의 리뷰를 수집하여 품목이 무엇인지, 누가 해당 품목을 만들었는지, 긍정 및 부정 감성을 파악하고 특정 품목 또는 특정 제조업체에 대한 긍정 또는 부정 감성에 대한 추세를 추적하는 데 유용할 수 있습니다. 이 예제에서는 항목과 브랜드를 키로 사용하여 응답 형식을 JSON 객체로 지정하도록 요청하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "  \"Item\": \"lamp\",\n",
    "  \"Brand\": \"Lumina\"\n",
    "}\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so, if I do that, it says the item is a lamp, the brand is Luminar, and you can easily load this into the Python dictionary to then do additional processing on this output. In the examples we've gone through, you saw how to write a prompt to recognize the sentiment, figure out if someone is angry, and then also extract the item and the brand.\n",
    "\n",
    "이렇게 하면 아이템은 램프, 브랜드는 Luminar라고 표시되며, 이를 Python 사전으로 쉽게 로드하여 이 출력에 대한 추가 처리를 수행할 수 있습니다. 지금까지 살펴본 예제에서는 감정을 인식하는 프롬프트를 작성하고, 누군가가 화를 냈는지 파악한 다음, 아이템과 브랜드를 추출하는 방법을 살펴봤습니다. \n",
    "\n",
    "One way to extract all of this information, would be to use 3 or 4 prompts and call getCompletion, you know, 3 times or 4 times, extract these different fields one at a time, but it turns out you can actually write a single prompt to extract all of this information at the same time.\n",
    "\n",
    "이 모든 정보를 추출하는 한 가지 방법은 프롬프트 3~4개를 사용하고 getCompletion을 3번 또는 4번 호출하여 한 번에 하나씩 다른 필드를 추출하는 것이지만, 실제로는 프롬프트 하나를 작성하여 모든 정보를 동시에 추출할 수 있다는 것을 알 수 있습니다.\n",
    "\n",
    "## Doing multiple tasks at once\n",
    "\n",
    "So, let's say, identify the fine items, extract sentiment, uhm, as a reviewer, expressing anger, item purchase, completely made it, uhm, and then here, I'm also going to tell it to format the anger value as a, as a boolean value, and let me run that, and this outputs a, uhm, JSON, where sentiment is positive, anger, and there are no quotes around false, because it asks it to just output it as a boolean value, uhm, it extracted the item as a lamp with additional storage instead of lamp, seems okay, but this way, you can extract multiple \n",
    "fields out of a piece of text with just a single prompt.\n",
    "\n",
    "그래서 좋은 아이템을 식별하고, 감정을 추출하고, 리뷰어로서 분노를 표현하고, 아이템을 구매하고, 완료했습니다. 그리고 여기에서 분노 값을 부울 값으로 형식화하도록 지시하고 실행해 보겠습니다. 그러면 감정이 긍정적 인 JSON이 출력됩니다, 분노, 그리고 거짓 주위에 따옴표가 없습니다. 그냥 부울 값으로 출력하라고 요청하기 때문에 램프 대신 추가 저장소가있는 램프로 항목을 추출했습니다. 괜찮아 보이지만 이렇게하면 단일 프롬프트만으로 텍스트 조각에서 여러 필드를 추출 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "  \"Sentiment\": \"positive\",\n",
    "  \"Anger\": false,\n",
    "  \"Item\": \"lamp with additional storage\",\n",
    "  \"Brand\": \"Lumina\"\n",
    "}\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as usual, please feel free to pause the video and play with different variations on this yourself, or maybe even try typing in a totally different review to see if you can still extract these things accurately.\n",
    "\n",
    "그리고 평소와 같이 동영상을 일시 정지하고 직접 다양한 변형을 시도해 보거나 완전히 다른 리뷰를 입력하여 이러한 내용을 정확하게 추출할 수 있는지 확인해 보세요.\n",
    "\n",
    "## Inferring topics\n",
    "\n",
    "Now, one of the cool applications I've seen of large language models is inferring topics. Given a long piece of text, you know, what is this piece of text about? What are the topics? Here's a fictitious newspaper article about how government workers feel about the agency they work for.\n",
    "\n",
    "제가 본 대규모 언어 모델의 멋진 활용 사례 중 하나는 주제 추론입니다. 긴 텍스트가 주어졌을 때, 이 텍스트는 무엇에 관한 것일까요? 주제는 무엇일까요? 다음은 공무원들이 자신이 근무하는 기관에 대해 어떻게 생각하는지에 대한 가상의 신문 기사입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government, \n",
    "public sector employees were asked to rate their level \n",
    "of satisfaction with the department they work at. \n",
    "The results revealed that NASA was the most popular \n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, \n",
    "stating, \"I'm not surprised that NASA came out on top. \n",
    "It's a great place to work with amazing people and \n",
    "incredible opportunities. I'm proud to be a part of \n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, \n",
    "with Director Tom Johnson stating, \"We are thrilled to \n",
    "hear that our employees are satisfied with their work at NASA. \n",
    "We have a talented and dedicated team who work tirelessly \n",
    "to achieve our goals, and it's fantastic to see that their \n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the \n",
    "Social Security Administration had the lowest satisfaction \n",
    "rating, with only 45% of employees indicating they were \n",
    "satisfied with their job. The government has pledged to \n",
    "address the concerns raised by employees in the survey and \n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the recent survey conducted by government, you know, and so on, uh, results reviewed at NASA was a popular department with high satisfaction rating. I am a fan of NASA, I love the work they do, but this is a fictitious article. And so, given an article like this, we can ask it, with this prompt, determine five topics that are being discussed in the following text.\n",
    "\n",
    "최근 정부 등에서 실시한 설문조사 결과, NASA는 만족도가 높은 인기 부서였습니다. 저는 NASA의 팬이고 그들이 하는 일을 좋아하지만 이것은 가상의 기사입니다. 따라서 이런 기사가 주어졌을 때 다음 텍스트에서 논의되고 있는 다섯 가지 주제를 결정하도록 요청할 수 있습니다.\n",
    "\n",
    "## Infer 5 topics\n",
    "\n",
    "Let's make each item one or two words long, format your response in a comma-separated list, and so if we run that, you know, we get out this article is about a government survey, it's about job satisfaction, it's about NASA, and so on.\n",
    "\n",
    "각 항목을 한두 단어 길이로 만들고 쉼표로 구분된 목록으로 응답 형식을 지정한 다음 실행하면 이 기사는 정부 설문조사에 관한 것이고, 직업 만족도에 관한 것이고, NASA에 관한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "government survey, job satisfaction, NASA, Social Security Administration, employee concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "response.split(sep=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['government survey',\n",
    " ' job satisfaction',\n",
    " ' NASA',\n",
    " ' Social Security Administration',\n",
    " ' employee concerns']\n",
    "\n",
    " ---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, overall, I think pretty nice, um, extraction of a list of topics, and of course, you can also, you know, split it so you get, uh, pie to the list with the five topics that, uh, this article was about. \n",
    "\n",
    "따라서 전반적으로 주제 목록을 추출하는 것은 매우 훌륭하다고 생각하며, 물론이를 분할하여이 기사의 다섯 가지 주제에 대한 파이를 목록에 넣을 수도 있습니다.\n",
    "\n",
    "And if you have a collection of articles and extract topics, you can then also use a large language model to help you index into different topics. So, let me use a slightly different topic list. Let's say that, um, we're a news website or something, and, you know, these are the topics we track, NASA, local government, engineering, employee satisfaction, federal government. And let's say you want to figure out, given a news article, which of these topics are covered in that news article.\n",
    "\n",
    "또한 문서 모음과 추출 토픽이 있는 경우 대규모 언어 모델을 사용하여 다양한 토픽으로 색인화할 수도 있습니다. 약간 다른 주제 목록을 사용하겠습니다. 뉴스 웹사이트라고 가정하고, 우리가 추적하는 토픽이 NASA, 지방 정부, 엔지니어링, 직원 만족도, 연방 정부라고 가정해 보겠습니다. 그리고 뉴스 기사가 주어졌을 때 해당 뉴스 기사에서 어떤 주제를 다루고 있는지 파악하고 싶다고 가정해 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "topic_list = [\n",
    "    \"nasa\", \"local government\", \"engineering\", \n",
    "    \"employee satisfaction\", \"federal government\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a news alert for certain topics\n",
    "\n",
    "So, here's a prompt that I can use. I'm going to say, determine whether each item in the following list of topics is a topic in the text below. Um, give your answer as a list of zero or one for each topic. And so, great. So, this is the same story text as before. So, this thing's a story. It is about NASA. It's not about local governments, not about engineering. It is about employee satisfaction, and it is about federal government.\n",
    "\n",
    "그래서 여기에 제가 사용할 수 있는 프롬프트가 있습니다. 다음 주제 목록의 각 항목이 아래 텍스트의 주제에 해당하는지 판단해 보겠습니다. 각 주제에 대해 0 또는 1의 목록으로 답해 주세요. 좋아요. 이것은 이전과 동일한 스토리 텍스트입니다. 이것은 이야기입니다. 나사에 관한 이야기입니다. 지방 정부에 관한 것도 아니고 엔지니어링에 관한 것도 아닙니다. 직원 만족도에 관한 이야기이며 연방 정부에 관한 이야기입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic.\\\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nasa: 1\n",
    "\n",
    "local government: 0\n",
    "\n",
    "engineering: 0\n",
    "\n",
    "employee satisfaction: 1\n",
    "\n",
    "federal government: 1\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with this, in machine learning, this is sometimes called a zero shot learning algorithm because we didn't give it any training data that was labeled. So, that's zero shot. And with just a prompt, it was able to determine which of these topics are covered in that news article. And so, if you want to generate a news alert, say, so that process news, and you know, I really like a lot of work that NASA does. So, if you want to build a system that can take this, you know, put this information into a dictionary, and whenever NASA news pops up, print alert, new NASA story, they can use this to very quickly take any article, figure out what topics it is about, and if the topic includes NASA, have it print out alert, new NASA story. Just one thing, I use this topic dictionary down here.\n",
    "\n",
    "따라서 머신 러닝에서는 레이블이 지정된 학습 데이터를 제공하지 않았기 때문에 이를 제로 샷 학습 알고리즘이라고 부르기도 합니다. 즉, 제로 샷입니다. 그리고 프롬프트만으로 해당 뉴스 기사에서 어떤 주제를 다루고 있는지 판단할 수 있었습니다. 따라서 뉴스 알림을 생성하고 싶다면, 예를 들어 뉴스를 처리하는 뉴스를 생성하고 싶다면, 저는 NASA가 하는 많은 작업을 정말 좋아합니다. 따라서 이 정보를 사전으로 가져와서 NASA 뉴스가 나올 때마다 알림, 새로운 NASA 스토리를 인쇄할 수 있는 시스템을 구축하려는 경우, 이를 사용하여 매우 빠르게 기사를 가져와서 어떤 주제에 관한 것인지 파악하고 주제에 NASA가 포함되면 알림, 새로운 NASA 스토리를 인쇄하도록 할 수 있습니다. 한 가지 더, 저는 이 주제 사전을 여기에 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\n",
    "if topic_dict['nasa'] == 1:\n",
    "    print(\"ALERT: New NASA story!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALERT: New NASA story!\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prompt that I use up here isn't very robust. If I went to the production system, I would probably have it output the answer \n",
    "in JSON format rather than as a list because the output of the large language model can be a little bit inconsistent.\n",
    "\n",
    "여기서 사용하는 이 프롬프트는 그다지 강력하지 않습니다. 프로덕션 시스템으로 넘어가면 큰 언어 모델의 출력이 약간 일관되지 않을 수 있기 때문에 아마 목록이 아닌 JSON 형식으로 답을 출력하도록 할 것입니다.\n",
    "\n",
    "So, this is actually a pretty brittle piece of code. But if you want, when you're done watching this video, feel free to see if you can figure out how to modify this prompt to have it output JSON instead of a list like this and then have a more robust way to tell if a bigger article is a story about NASA.\n",
    "\n",
    "따라서 이것은 실제로 꽤 깨지기 쉬운 코드입니다. 하지만 이 동영상을 다 보신 후에 이 프롬프트를 수정하여 이와 같은 목록 대신 JSON을 출력하도록 하고, 더 큰 기사가 NASA에 대한 기사임을 더 강력하게 알 수 있는 방법을 알아낼 수 있는지 확인해 보시기 바랍니다. \n",
    "\n",
    "So, that's it for inferring, and in just a few minutes, you can build multiple systems for making inferences about text that previously this would have taken days or even weeks for a skilled machine learning developer. And so, I find this very exciting that both for skilled machine learning developers as well as for people that are newer to machine learning, you can now use prompting to very quickly build and start making inferences on pretty complicated natural language processing tasks like these. In the next video, we'll continue to talk about exciting things you can do with large language models and we'll go on to transforming. How can you take one piece of text and transform it into a different piece of text such as translated to a different language? Let's go on to the next video.\n",
    "\n",
    "이제 추론은 여기까지이며, 이전에는 숙련된 머신 러닝 개발자가 며칠 또는 몇 주가 걸렸을 텍스트에 대한 추론을 위한 여러 시스템을 단 몇 분 만에 구축할 수 있습니다. 따라서 숙련된 머신 러닝 개발자뿐만 아니라 머신 러닝을 처음 접하는 사람들도 이제 프롬프트를 사용하여 이와 같이 매우 복잡한 자연어 처리 작업을 매우 빠르게 구축하고 추론을 시작할 수 있다는 점이 매우 흥미롭습니다. 다음 동영상에서는 대규모 언어 모델로 할 수 있는 흥미로운 작업들에 대해 계속해서 이야기해 보겠습니다. 하나의 텍스트를 다른 언어로 번역하는 등 다른 텍스트로 변환하려면 어떻게 해야 할까요? 다음 동영상으로 넘어가겠습니다. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
